{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération des tweets et articles en rapport au marché boursier US via les API \n",
    "\n",
    "**Projet Python - 2A ENSAE** . \n",
    "\n",
    "Elena Loumagne / Jérémie Darracq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Ce notebook a été créé pour les requètes via les API. Nous avons eu besoin d'un compte FinHub et d'un compte twitter pour obtenir nos clef. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeremiedarracq/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jeremiedarracq/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/jeremiedarracq/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jeremiedarracq/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pour la récupération des données\n",
    "#%pip install finnhub-python\n",
    "import finnhub\n",
    "import pandas as pd \n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "## Pour le preprocessing\n",
    "#%pip install demoji\n",
    "#%pip install nltk\n",
    "\n",
    "import demoji\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des article via l'API de Finhub\n",
    "Dans cette section, on définit les fonctions permettant la connexion à l'API finhub et la récupération des données selon les termes clés, les dates et d'autres caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui transforme les données fournit par l'API en un dictionnaire \n",
    "def get_data(article):\n",
    "    data = {\n",
    "        'date': time.strftime(\"%D %H:%M\", time.localtime(article['datetime'])),\n",
    "        'headline': article['headline'],\n",
    "        'company': article['related'],\n",
    "        'abstract': article['summary'],\n",
    "        'source': article['source']\n",
    "    }\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finnhub_client = finnhub.Client(api_key=\"ce74bdiad3iakcsvp120ce74bdiad3iakcsvp12g\")  ## Fonction d'appel à l'API\n",
    "\n",
    "start_date = \"2022-10-01\" ## Date du début de la requête \n",
    "end_date = \"2022-12-05\"  ## Date de fin de la requête \n",
    "\n",
    "## Liste des companies du SP500 apparaissant dans les articles \n",
    "\n",
    "List_company = ['AMZN','AAPL','MSFT','META','JPM','JNJ','GOOGL','PFE','BAC','NFLX','MA','MCD','GS','INTC','TMUS','WMT','CBOE','MRK','WFC','BA','MRNA','NDAQ','NKE','SLB','TSLA','VZ','T','AXP','BRK.B','CAT','CVX','KO','EA','FDX','GE','IBM','UNH','XOM','NVDA','PEP','COST','DIS','PM','ATVI','ADBE','AAL','AIG','BIIB','AVGO','COF']\n",
    "\n",
    "## Pour chaque companie nous effectuons un appel à l'API \n",
    "\n",
    "df = pd.DataFrame() \n",
    "for symbol in List_company :\n",
    "    response = finnhub_client.company_news(symbol, _from= start_date, to=end_date)\n",
    "    for article in response:\n",
    "        row = get_data(article) \n",
    "        df = df.append(row, ignore_index=True)\n",
    "\n",
    "## On stock la base de donné fournit par Finhub \n",
    "\n",
    "df.to_csv(\"Data/data_finhub.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On modifie le format de la date \n",
    "df[\"date\"]=df[\"date\"].apply(lambda x : x[0:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing des articles Finhub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fonction qui nettoie le texte\n",
    "def transform(texte):\n",
    "    texte = texte.lower() # mettre les mots en minuscule\n",
    "    for item in re.compile(\"([#]\\w+)\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retirer les apostrophes '\n",
    "    for item in re.compile(\"([\\’])\").findall(texte):\n",
    "        texte=texte.replace(item, \" \")\n",
    "    for item in re.compile(\"([\\'])\").findall(texte):\n",
    "        texte=texte.replace(item, \" \")\n",
    "    # retirer les points de suspension\n",
    "    for item in re.compile(\"([.]{1,5})\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    texte = re.sub(r\"[A-Za-z\\.]*[0-9]+[A-Za-z%°\\.]*\", \"\", texte)\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On nettoie les résumés des articles \n",
    "df[\"abstract_clean\"]=df[\"abstract\"].apply(lambda x : transform(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  fonction qui supprime les petits mots non pertinent pour l'analse ( ex: you,the )\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def retrait_sw(text):\n",
    "    return ' '.join([word for word in text.split() if word.casefold() not in stopwords ])\n",
    "\n",
    "df[\"abstract_clean\"] = df[\"abstract_clean\"].apply(retrait_sw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>source</th>\n",
       "      <th>abstract_clean</th>\n",
       "      <th>abstract_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A report on the state of the service sector fu...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>12/05/22</td>\n",
       "      <td>Why Amazon, Okta, and Roku Stocks All Slumped ...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>report state service sector fueled fears feder...</td>\n",
       "      <td>report state servic sector fuel fear feder res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yahoo Finance tech editor Dan Howley outlines ...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>12/05/22</td>\n",
       "      <td>Apple and Amazon resume Twitter advertising</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>yahoo finance tech editor dan howley outlines ...</td>\n",
       "      <td>yahoo financ tech editor dan howley outlin app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon's (AMZN) AWS is chosen by Yahoo as the ...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>12/05/22</td>\n",
       "      <td>Amazon's (AMZN) AWS Gets Selected by Yahoo, Bo...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>amazon (amzn) aws chosen yahoo preferred publi...</td>\n",
       "      <td>amazon (amzn) aw chosen yahoo prefer public cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shares of Amazon.com Inc. shed 3.31% to $91.01...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>12/05/22</td>\n",
       "      <td>Amazon.com Inc. stock underperforms Monday whe...</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>shares amazoncom inc shed $ monday, proved all...</td>\n",
       "      <td>share amazoncom inc shed $ monday, prove all-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Triumph Technology Solutions, which has experi...</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>12/05/22</td>\n",
       "      <td>After explosive growth, Philadelphia tech star...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>triumph technology solutions, experienced year...</td>\n",
       "      <td>triumph technolog solutions, experienc year-ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10833</th>\n",
       "      <td>The hack compromised about 140,000 Social Secu...</td>\n",
       "      <td>COF</td>\n",
       "      <td>10/06/22</td>\n",
       "      <td>Former Amazon cloud engineer gets probation fo...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>hack compromised , social security numbers , b...</td>\n",
       "      <td>hack compromis , social secur number , bank ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10834</th>\n",
       "      <td>On Thursday, October 27, 2022, at approximatel...</td>\n",
       "      <td>COF</td>\n",
       "      <td>10/05/22</td>\n",
       "      <td>Capital One Financial Corporation to Webcast C...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>thursday, october , , approximately : pm easte...</td>\n",
       "      <td>thursday, octob , , approxim : pm eastern time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10835</th>\n",
       "      <td>RIVN stock is up after Rivian announced it pro...</td>\n",
       "      <td>COF</td>\n",
       "      <td>10/04/22</td>\n",
       "      <td>Why Is RIVN Stock Up Today? Rivian Confirmed 2...</td>\n",
       "      <td>InvestorPlace</td>\n",
       "      <td>rivn stock rivian announced produced , vehicle...</td>\n",
       "      <td>rivn stock rivian announc produc , vehicl trac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10836</th>\n",
       "      <td>Big bank stocks are down 27% on average, but a...</td>\n",
       "      <td>COF</td>\n",
       "      <td>10/03/22</td>\n",
       "      <td>Q3 2022 Bank Analysts' Top 3 Picks, Earnings E...</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>big bank stocks average, analysts see sunny da...</td>\n",
       "      <td>big bank stock average, analyst see sunni day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10837</th>\n",
       "      <td>Item 8.01 Other Events.On October 1, 2022, Cap...</td>\n",
       "      <td>COF</td>\n",
       "      <td>10/03/22</td>\n",
       "      <td>CAPITAL ONE FINANCIAL CORP : Other Events, Fin...</td>\n",
       "      <td>Finnhub</td>\n",
       "      <td>item eventson october , , capital one financia...</td>\n",
       "      <td>item eventson octob , , capit one financi corp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10838 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract company      date  \\\n",
       "0      A report on the state of the service sector fu...    AMZN  12/05/22   \n",
       "1      Yahoo Finance tech editor Dan Howley outlines ...    AMZN  12/05/22   \n",
       "2      Amazon's (AMZN) AWS is chosen by Yahoo as the ...    AMZN  12/05/22   \n",
       "3      Shares of Amazon.com Inc. shed 3.31% to $91.01...    AMZN  12/05/22   \n",
       "4      Triumph Technology Solutions, which has experi...    AMZN  12/05/22   \n",
       "...                                                  ...     ...       ...   \n",
       "10833  The hack compromised about 140,000 Social Secu...     COF  10/06/22   \n",
       "10834  On Thursday, October 27, 2022, at approximatel...     COF  10/05/22   \n",
       "10835  RIVN stock is up after Rivian announced it pro...     COF  10/04/22   \n",
       "10836  Big bank stocks are down 27% on average, but a...     COF  10/03/22   \n",
       "10837  Item 8.01 Other Events.On October 1, 2022, Cap...     COF  10/03/22   \n",
       "\n",
       "                                                headline         source  \\\n",
       "0      Why Amazon, Okta, and Roku Stocks All Slumped ...          Yahoo   \n",
       "1            Apple and Amazon resume Twitter advertising          Yahoo   \n",
       "2      Amazon's (AMZN) AWS Gets Selected by Yahoo, Bo...          Yahoo   \n",
       "3      Amazon.com Inc. stock underperforms Monday whe...    MarketWatch   \n",
       "4      After explosive growth, Philadelphia tech star...          Yahoo   \n",
       "...                                                  ...            ...   \n",
       "10833  Former Amazon cloud engineer gets probation fo...          Yahoo   \n",
       "10834  Capital One Financial Corporation to Webcast C...          Yahoo   \n",
       "10835  Why Is RIVN Stock Up Today? Rivian Confirmed 2...  InvestorPlace   \n",
       "10836  Q3 2022 Bank Analysts' Top 3 Picks, Earnings E...   SeekingAlpha   \n",
       "10837  CAPITAL ONE FINANCIAL CORP : Other Events, Fin...        Finnhub   \n",
       "\n",
       "                                          abstract_clean  \\\n",
       "0      report state service sector fueled fears feder...   \n",
       "1      yahoo finance tech editor dan howley outlines ...   \n",
       "2      amazon (amzn) aws chosen yahoo preferred publi...   \n",
       "3      shares amazoncom inc shed $ monday, proved all...   \n",
       "4      triumph technology solutions, experienced year...   \n",
       "...                                                  ...   \n",
       "10833  hack compromised , social security numbers , b...   \n",
       "10834  thursday, october , , approximately : pm easte...   \n",
       "10835  rivn stock rivian announced produced , vehicle...   \n",
       "10836  big bank stocks average, analysts see sunny da...   \n",
       "10837  item eventson october , , capital one financia...   \n",
       "\n",
       "                                        abstract_stemmed  \n",
       "0      report state servic sector fuel fear feder res...  \n",
       "1      yahoo financ tech editor dan howley outlin app...  \n",
       "2      amazon (amzn) aw chosen yahoo prefer public cl...  \n",
       "3      share amazoncom inc shed $ monday, prove all-a...  \n",
       "4      triumph technolog solutions, experienc year-ov...  \n",
       "...                                                  ...  \n",
       "10833  hack compromis , social secur number , bank ac...  \n",
       "10834  thursday, octob , , approxim : pm eastern time...  \n",
       "10835  rivn stock rivian announc produc , vehicl trac...  \n",
       "10836  big bank stock average, analyst see sunni day ...  \n",
       "10837  item eventson octob , , capit one financi corp...  \n",
       "\n",
       "[10838 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## On \"stem\" les résumés des articles pour ne garder que la racine des mots \n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "df[\"abstract_stemmed\"]=df[\"abstract_clean\"].apply(lambda x : ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des article via l'API de Twitter\n",
    "Dans cette section, on définit les fonctions permettant la connexion à l'API twitter et la récupération des données selon les termes clés, les dates et d'autres caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAEHijwEAAAAA5k533gmjemyLZvGcHJ85KptB2ag%3DakjvNX75aeG15S5hKt8tVPniNlrXN0DihoVURgMjmoXXcr7e6M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tweet):\n",
    "    data = {\n",
    "        'date': tweet['created_at'],\n",
    "        'text': tweet['text']\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appel à l'API\n",
    "endpoint = 'https://api.twitter.com/2/tweets/search/recent'\n",
    "headers = {'authorization': f'Bearer {BEARER_TOKEN}'}\n",
    "params = {\n",
    "    'query': '(VIX OR S&P 500 OR CBOE OR investement OR stock market OR Federal Reserve Bank OR stock price OR inflation OR bonds ) (lang:en)',\n",
    "    'max_results': '100',\n",
    "    'tweet.fields': 'created_at,lang'\n",
    "}\n",
    "\n",
    "\n",
    "dtformat = '%Y-%m-%dT%H:%M:%S.000Z'  # le format de la date recquis par l'API Twitter\n",
    "\n",
    "def time_travel(now, mins):\n",
    "    '''\n",
    "    Permet de modifier de date\n",
    "\n",
    "    'now : str \n",
    "        date actuelle\n",
    "    \n",
    "    'mins : int\n",
    "        minutes à soustraire\n",
    "    '''\n",
    "\n",
    "    now = datetime.strptime(now, dtformat)\n",
    "    back_in_time = now - timedelta(minutes=mins)\n",
    "    return back_in_time.strftime(dtformat)\n",
    "    \n",
    "now = datetime.now() # date actuel\n",
    "last_week = now - timedelta(days=7)  # date de fin\n",
    "now = now.strftime(dtformat)  # convertit la date au format de l'API\n",
    "\n",
    "\n",
    "now=time_travel(now,60)\n",
    "df_tweet = pd.DataFrame()  \n",
    "\n",
    "time.sleep(20)\n",
    "\n",
    "\n",
    "while True:\n",
    "    if datetime.strptime(now, dtformat) < last_week:\n",
    "        # si on atteint les 7 jours, on sort de la boucle\n",
    "        break\n",
    "    pre60 = time_travel(now, 30)  \n",
    "    \n",
    "    params['start_time'] = pre60\n",
    "    params['end_time'] = now\n",
    "    response = requests.get(endpoint,\n",
    "                            params=params,\n",
    "                            headers=headers)  # envoie de la requête\n",
    "    now = pre60  # on voyage 60 min avant pour récupérer un maximum de tweet sur chaque heure\n",
    "\n",
    "    # on ajoute les tweets à notre df\n",
    "    for tweet in response.json()['data']:\n",
    "        row = get_data(tweet)  \n",
    "        df_tweet = df_tweet.append(row, ignore_index=True)\n",
    "\n",
    "df_tweet.to_csv(\"Data/tweet.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing des Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on supprime tous les pseudos qui comportent le mot vix car cela ne correspond pas aux tweet sur la finance\n",
    "for index,row in df_tweet.iterrows():\n",
    "    tweet=row[\"text\"]\n",
    "    real_pseudo=[]\n",
    "    \n",
    "    for word in tweet.split():\n",
    "        if '@' in word:\n",
    "            real_pseudo.append(word)\n",
    "\n",
    "    vix_in_pseudo=[\"vix\" in pseudo.lower() for pseudo in real_pseudo]\n",
    "\n",
    "    if True in vix_in_pseudo:\n",
    "        df_tweet.drop(index, inplace=True)\n",
    "\n",
    "df_tweet.reset_index(inplace=True,drop=True)\n",
    "\n",
    "## on modifie la date \n",
    "df_tweet[\"date\"]=df_tweet[\"date\"].apply(lambda x : x[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction qui nettoie les tweets\n",
    "def transform_tweet(texte):\n",
    "    texte = texte.lower() # mettre les mots en minuscule\n",
    "    #retirer les liens\n",
    "    for item in re.compile(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # enlever le retour à la ligne\n",
    "    texte = texte.replace(\"\\n\", \" \").replace(\"\\r\", \"\") \n",
    "    # supprimer \",\", \"!\", \"?\", \"%\", \"(\",\")\",\"/\",'\"', \"$\",\"£\", \"_\", \"-\", \"+\", \"*\", \"µ\", \":\",\"&,\"§\" \n",
    "    texte = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\\"\\$\\£\\+\\*\\µ,\\:\\&\\§]\", \" \", texte) \n",
    "    # retirer les hashtags #\n",
    "    for item in re.compile(\"([#]\\w+)\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retirer les apostrophes '\n",
    "    for item in re.compile(\"([\\’])\").findall(texte):\n",
    "        texte=texte.replace(item, \" \")\n",
    "    for item in re.compile(\"([\\'])\").findall(texte):\n",
    "        texte=texte.replace(item, \" \")\n",
    "    # retirer les points de suspension\n",
    "    for item in re.compile(\"([.]{1,5})\").findall(texte):\n",
    "        texte=texte.replace(item, \"\") \n",
    "    # retirer les personnes tagées\n",
    "    for item in re.compile(\"([@]\\w+)\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retirer les adresses mail\n",
    "    for item in re.findall('\\S+@\\S+', texte) :\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retire les mots contenant des chiffres\n",
    "    texte = re.sub(r\"[A-Za-z\\.]*[0-9]+[A-Za-z%°\\.]*\", \"\", texte)\n",
    "    # retirer les emojis\n",
    "    for item in demoji.findall(texte):\n",
    "        texte=texte.replace(item,\"\")\n",
    "    return texte\n",
    "\n",
    "df_tweet[\"tweet_clean\"]=df_tweet[\"text\"].apply(lambda x : transform_tweet(x))\n",
    "\n",
    "## on retire les stopswords\n",
    "word_to_del = []\n",
    "stop_words = stopwords.words('english') + word_to_del\n",
    "\n",
    "def retrait_sw(text):\n",
    "    return ' '.join([word for word in text.split() if word.casefold() not in stop_words ])\n",
    "\n",
    "df_tweet[\"tweet_clean\"] = df_tweet[\"tweet_clean\"].apply(retrait_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## on \"stem\" les tweets\n",
    "df_tweet[\"tweet_stemmed\"]=df_tweet[\"tweet_clean\"].apply(lambda x : ' '.join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93257c97269dad6db5a0bed4f581319771fe589ffe8644d312475ce335138545"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
